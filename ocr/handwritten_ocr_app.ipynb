{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 인식 Application\n",
    "Colab 환경에서 손글씨 인식 애플리케이션을 만들어봅시다. 애플리케이션 사용자의 유스케이스는 아래와 같습니다.\n",
    "- 사용자는 손글씨 이미지 파일을 업로드할 수 있다.\n",
    "- 사용자는 캔버스에 손글씨를 쓸 수 있다.\n",
    "- 사용자는 텍스트 결과를 확인할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab 환경 설정\n",
    "python package들을 설치합니다. 예제로 사용할 이미지들도 다운로드 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local에서 Run하는 경우 False로 변경\n",
    "using_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    !wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/ocr/requirements.txt\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    !mkdir examples\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Hello.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Hello_cursive.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Red.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/sentence.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/i_love_you.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/merrychristmas.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Rock.png\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/ocr/examples/Bob.png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 업로드 UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")\n",
    "    image = gr.Image(label=\"Handwritten image file\")\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "    convert_btn = gr.Button(\"Convert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrOCR 추론기 클래스\n",
    "TrOCR 추론기 클래스는 TrOCR 모델 및 processor 초기화와 추론 작업을 수행하는 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrOCRInferencer:\n",
    "    def __init__(self):\n",
    "        print(\"[INFO] Initialize TrOCR Inferencer.\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "\n",
    "    def inference(self, image: Image) -> str:\n",
    "        \"\"\"Inference using model.\n",
    "\n",
    "        It is performed as a procedure of preprocessing - inference - postprocessing.\n",
    "        \"\"\"\n",
    "        # preprocess\n",
    "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "        # inference\n",
    "        generated_ids = self.model.generate(pixel_values)\n",
    "        # postprocess\n",
    "        generated_text = self.processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "\n",
    "inferencer = TrOCRInferencer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_text(image: np.ndarray) -> str:\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "    text = inferencer.inference(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")\n",
    "    image = gr.Image(label=\"Handwritten image file\")\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "    convert_btn = gr.Button(\"Convert\")\n",
    "    convert_btn.click(\n",
    "        fn=image_to_text, inputs=image, outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캔버스 UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")\n",
    "    sketchpad = gr.Sketchpad(\n",
    "        label=\"Handwritten Sketchpad\",\n",
    "        shape=(600, 192),\n",
    "        brush_radius=2,\n",
    "        invert_colors=False,\n",
    "    )\n",
    "    output = gr.Textbox(label=\"Output Box\")\n",
    "    convert_btn = gr.Button(\"Convert\")\n",
    "    convert_btn.click(\n",
    "        fn=image_to_text, inputs=sketchpad, outputs=output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 App 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement inferencer\n",
    "class TrOCRInferencer:\n",
    "    def __init__(self):\n",
    "        print(\"[INFO] Initialize TrOCR Inferencer.\")\n",
    "        self.processor = TrOCRProcessor.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\n",
    "            \"microsoft/trocr-base-handwritten\"\n",
    "        )\n",
    "\n",
    "    def inference(self, image: Image) -> str:\n",
    "        \"\"\"Inference using model.\n",
    "\n",
    "        It is performed as a procedure of preprocessing - inference - postprocessing.\n",
    "        \"\"\"\n",
    "        # preprocess\n",
    "        pixel_values = self.processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "        # inference\n",
    "        generated_ids = self.model.generate(pixel_values)\n",
    "        # postprocess\n",
    "        generated_text = self.processor.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True\n",
    "        )[0]\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "inferencer = TrOCRInferencer()\n",
    "\n",
    "\n",
    "# Implement event function\n",
    "def image_to_text(image: np.ndarray) -> str:\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "    text = inferencer.inference(image)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Implement app\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Handwritten Image OCR\")\n",
    "    with gr.Tab(\"Image upload\"):\n",
    "        image = gr.Image(label=\"Handwritten image file\")\n",
    "        output = gr.Textbox(label=\"Output Box\")\n",
    "        convert_btn = gr.Button(\"Convert\")\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=image, outputs=output\n",
    "        )\n",
    "\n",
    "        gr.Markdown(\"## Image Examples\")\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                os.path.join(os.getcwd(), \"examples/Hello.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Hello_cursive.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Red.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/sentence.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/i_love_you.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/merrychristmas.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Rock.png\"),\n",
    "                os.path.join(os.getcwd(), \"examples/Bob.png\"),\n",
    "            ],\n",
    "            inputs=image,\n",
    "            outputs=output,\n",
    "            fn=image_to_text,\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Drawing\"):\n",
    "        sketchpad = gr.Sketchpad(\n",
    "            label=\"Handwritten Sketchpad\",\n",
    "            shape=(600, 192),\n",
    "            brush_radius=2,\n",
    "            invert_colors=False,\n",
    "        )\n",
    "        output = gr.Textbox(label=\"Output Box\")\n",
    "        convert_btn = gr.Button(\"Convert\")\n",
    "        convert_btn.click(\n",
    "            fn=image_to_text, inputs=sketchpad, outputs=output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App 실행\n",
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
