{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경 제거 Application\n",
    "\n",
    "Colab 환경에서 배경 제거 애플리케이션을 만들어봅시다. 애플리케이션 사용자의 유스케이스는 아래와 같습니다.\n",
    "\n",
    "- 사용자는 이미지 파일을 업로드할 수 있다.\n",
    "- 사용자는 이미지에서 원하는 객체 클릭한다.\n",
    "- 사용자는 배경 제거 이미지의 결과를 확인하고 다운로드 받을 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab 환경 설정\n",
    "python package들을 설치합니다. 예제로 사용할 이미지들도 다운로드 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local에서 Run하는 경우 False로 변경\n",
    "using_colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    !wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/requirements.txt\n",
    "    !pip install -r requirements.txt\n",
    "    !wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/app.py\n",
    "\n",
    "    !mkdir examples\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/segmentation/examples/dog.jpg\n",
    "    !cd examples && wget https://github.com/mrsyee/dl_apps/raw/main/segmentation/examples/mannequin.jpg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
    "    with gr.Row():\n",
    "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
    "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
    "\n",
    "    with gr.Row():\n",
    "        input_img = gr.Image(label=\"Input image\").style(height=600)\n",
    "        output_img = gr.Image(label=\"Output image\").style(height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마우스 클릭 이벤트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(evt: gr.SelectData):\n",
    "    return evt.index[0], evt.index[1]\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Interactive Remove Background from Image\")\n",
    "    with gr.Row():\n",
    "        coord_x = gr.Number(label=\"Mouse coords x\")\n",
    "        coord_y = gr.Number(label=\"Mouse coords y\")\n",
    "\n",
    "    with gr.Row():\n",
    "        input_img = gr.Image(label=\"Input image\").style(height=600)\n",
    "        output_img = gr.Image(label=\"Output image\").style(height=600)\n",
    "\n",
    "    input_img.select(get_coords, None, [coord_x, coord_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM 추론기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(\"checkpoint\")\n",
    "CHECKPOINT_NAME = \"sam_vit_h_4b8939.pth\"\n",
    "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
    "MODEL_TYPE = \"default\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMInferencer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint_path: str,\n",
    "        checkpoint_name: str,\n",
    "        checkpoint_url: str,\n",
    "        model_type: str,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        print(\"[INFO] Initailize inferencer\")\n",
    "        if not os.path.exists(checkpoint_path):\n",
    "            os.makedirs(checkpoint_path, exist_ok=True)\n",
    "        checkpoint = os.path.join(checkpoint_path, checkpoint_name)\n",
    "        if not os.path.exists(checkpoint):\n",
    "            urllib.request.urlretrieve(checkpoint_url, checkpoint)\n",
    "        sam = sam_model_registry[model_type](checkpoint=checkpoint).to(device)\n",
    "        self.predictor = SamPredictor(sam)\n",
    "\n",
    "    def inference(\n",
    "        self,\n",
    "        image: np.ndarray,\n",
    "        point_coords: np.ndarray,\n",
    "        points_labels: np.ndarray,\n",
    "    ) -> np.ndarray:\n",
    "        self.predictor.set_image(image)\n",
    "        masks, scores, _ = self.predictor.predict(point_coords, points_labels)\n",
    "        mask, score = self.select_masks(masks, scores, point_coords.shape[0])\n",
    "        return mask\n",
    "\n",
    "    def select_masks(\n",
    "        self, masks: np.ndarray, iou_preds: np.ndarray, num_points: int\n",
    "    ) -> Tuple [np.ndarray, np.ndarray]:\n",
    "        # Determine if we should return the multiclick mask or not from the number of points.\n",
    "        # The reweighting is used to avoid control flow.\n",
    "        # Reference: https://github.com/facebookresearch/segment-anything/blob/6fdee8f2727f4506cfbbe553e23b895e27956588/segment_anything/utils/onnx.py#L92-L105\n",
    "        score_reweight = np.array([1000] + [0] * 2)\n",
    "        score = iou_preds + (num_points - 2.5) * score_reweight\n",
    "        best_idx = np.argmax(score)\n",
    "        masks = np.expand_dims(masks[best_idx, :, :], axis=-1)\n",
    "        iou_preds = np.expand_dims(iou_preds[best_idx], axis=0)\n",
    "        return masks, iou_preds\n",
    "\n",
    "\n",
    "inferencer = SAMInferencer(\n",
    "    CHECKPOINT_PATH, CHECKPOINT_NAME, CHECKPOINT_URL, MODEL_TYPE, DEVICE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배경 제거 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_object(image: np.ndarray, point_h: int, point_w: int):\n",
    "    point_coords = np.array([[point_h, point_w], [0, 0]])\n",
    "    point_label = np.array([1, -1])\n",
    "\n",
    "    # Get mask\n",
    "    mask = inferencer.inference(image, point_coords, point_label)\n",
    "\n",
    "    # Extract object\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    return segmented_image\n",
    "\n",
    "\n",
    "def extract_object_by_event(image: np.ndarray, evt: gr.SelectData):\n",
    "    click_h, click_w = evt.index\n",
    "\n",
    "    return extract_object(image, click_h, click_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Interactive Extracting Object from Image\")\n",
    "    with gr.Row():\n",
    "        coord_h = gr.Number(label=\"Mouse coords h\")\n",
    "        coord_w = gr.Number(label=\"Mouse coords w\")\n",
    "\n",
    "    with gr.Row():\n",
    "        input_img = gr.Image(label=\"Input image\").style(height=600)\n",
    "        output_img = gr.Image(label=\"Output image\").style(height=600)\n",
    "\n",
    "    input_img.select(extract_object_by_event, [input_img], output_img)\n",
    "    input_img.select(get_coords, None, [coord_h, coord_w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
