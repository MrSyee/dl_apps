{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code of Segment Anything Model (SAM)\n",
    "\n",
    "Colab 환경에서 SAM 모델을 사용해 이미지에 클릭한 위치의 객체를 segmentation 하는 예제입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키지 및 예제 데이터 다운로드하기\n",
    "예제를 실행시키기 위해 python package들을 설치합니다. 예제로 사용할 이미지들도 다운로드 받습니다. Colab에서 실행하지 않는 경우 이 셀은 실행하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/requirements-colab.txt\n",
    "!pip install -r requirements-colab.txt\n",
    "\n",
    "# 예제 이미지 다운로드\n",
    "!mkdir examples\n",
    "!cd examples && wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/dog.jpg\n",
    "!cd examples && wget https://raw.githubusercontent.com/mrsyee/dl_apps/main/segmentation/examples/mannequin.jpg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from segment_anything import SamPredictor, sam_model_registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 학습 모델 불러오기\n",
    "\n",
    "[Segment Anything 라이브러리](https://github.com/facebookresearch/segment-anything)의 `SamPredictor` Class를 이용해 SAM 모델을 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(\"checkpoint\")\n",
    "CHECKPOINT_NAME = \"sam_vit_h_4b8939.pth\"\n",
    "CHECKPOINT_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "checkpoint = os.path.join(CHECKPOINT_PATH, CHECKPOINT_NAME)\n",
    "if not os.path.exists(checkpoint):\n",
    "    urllib.request.urlretrieve(CHECKPOINT_URL, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[\"vit_h\"](checkpoint=checkpoint).to(DEVICE)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"examples/mannequin.jpg\"\n",
    "image = cv2.imread(IMAGE_PATH, cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 포인트 좌표 입력 만들기\n",
    "\n",
    "원하는 위치의 객체를 segmentation 하기 위해서는 원하는 위치를 Point로 입력해야합니다. SAM 모델에 Point를 입력하기 위해서는 두 가지 정보가 필요합니다.\n",
    "\n",
    "- point_coords: Point 좌표 (x, y)\n",
    "- points_labels: Point의 타입. Point 위치의 객체를 선택하려면 Positive Click(1)로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coords = np.array([[1720, 230]])\n",
    "points_labels = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.gca().scatter(\n",
    "    point_coords[0, 0],\n",
    "    point_coords[0, 1],\n",
    "    color=\"green\",\n",
    "    marker=\"o\",\n",
    "    s=200,\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1.25,\n",
    ")\n",
    "plt.axis(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM 모델 추론하기\n",
    "\n",
    "predictor의 predict 함수를 통해 추론합니다. 추론의 결과로 2 가지 정보가 출력됩니다.\n",
    "- masks: 입력한 정보에 대해 3개의 mask가 출력.\n",
    "- scores: 3개의 mask의 퀄리티에 대한 모델의 평가 점수. 점수가 가장 높을수록 퀄리티가 높은 mask입니다.\n",
    "- low_res_logits: 저해상도 mask 출력. 이 예제에서는 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)\n",
    "masks, scores, _ = predictor.predict(point_coords, points_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mask in enumerate(masks):\n",
    "    print(f\"Mask {i}\")\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask)\n",
    "    plt.axis(\"on\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = np.array([30/255, 144/255, 255/255, 0.5])\n",
    "\n",
    "for mask in masks:\n",
    "    mask_image = np.expand_dims(mask, axis=-1) * color.reshape(1, 1, -1)\n",
    "    mask_image = (mask_image * 255).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(mask_image)\n",
    "    plt.axis(\"on\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 점수를 이용해 세그멘테이션 마스크 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = masks[np.argmax(scores)]\n",
    "\n",
    "color = np.array([30/255, 144/255, 255/255, 0.5])\n",
    "mask_image = np.expand_dims(mask, axis=-1) * color.reshape(1, 1, -1)\n",
    "mask_image = (mask_image * 255).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.imshow(mask_image)\n",
    "plt.axis(\"on\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
